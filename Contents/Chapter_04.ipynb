{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Chapter 04: Recursion",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 4.1: Illustrative Examples\n\n#### Binary Search\nThis section covers a recursive algorithm, binary search. When the sequence is unsorted, teh standard approach to search\nfor a target value is to use a loop to examine every element, until either finding the target or exhausting the \ndata set. This is known as the sequential search algorithm. This algorithm runs in $O(n)$ time since every element is \ninspected in the worst case.\n\nWhen the sequence is sorted and indexable, there is a much more efficient algorithm. For any index $j$, we know that all\n the values sorted at indices $0, \\ldots, j-1$ are less than or equal to the value at index $j$, and all the values\n sorted at indices $j+1, \\ldots, n-1$ are greater than or equal to that at index $j$.\n \n The algorithm maintains two parameters, `low` and `high` such that all the candidate entries have index at least\n `low` and at most `high`. Initially, `low \u003d 0` and `high \u003d n-1`. We then compare the target value to the median candidate,\n that is, the item `data[mid]` with index\n \n $$\\text{mid} \u003d \\left\\lfloor \\frac{( \\text{low} + \\text{high})}{2} \\right\\rfloor$$\n\n \nSimply we have to care these three case:\n* If the target equals `data[mid]`, then we have found the item we are looking for, and the search terminates successfully.\n* If `target \u003c data[mid]`, then we recur on the first half of the sequence, indices from $(0, \\text{mid} -1)$.\n* If `target \u003e data[mid]`, then we recur on the second half of the sequence, indices from $(\\text{mid} +1, \\text{high})$\n\nWhen `low \u003e high`, means the sequence does not have the value we are finding.\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "source": "def binary_search(data, target, low, high):\n    \"\"\"\n    Return True if target is found in indicated portion of a Python list\n    \n    The search only considers the portion from data[low] to data[high] inclusive.\n    \n    :param data: sequence that value will be searched\n    :param target: value to find\n    :param low: lower bound of sequence\u0027s index\n    :param high: upper bound of sequence\u0027s index\n    :return: \n    \"\"\"\n    \n    if low \u003e high:\n        return False\n    else:\n        mid \u003d (low + high) // 2\n        if target \u003d\u003d data[mid]:\n            return True\n        elif target \u003c data[mid]:\n            return binary_search(data, target, low, mid -1)\n        else:\n            return binary_search(data, target, mid+1, high)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 4.2: Analyzing Recursive Algorithms\n\nWith a recursive algorithm, we will account for each operation that is performed based upon the particular activation of\nthe function that manages the flow of control at the time it is executed. Stated another way, for each invocation of the function, we only\naccount for the number of operations that are performed within the body of that activation. We can then account for the overall number of operations that are executed as part of the\nrecursive algorithm by taking the sum, over all activations, of the number of operations that take place during each individual activation.\n\nIn general, we may rely on the intuition afforded by recursion trace in recognizing how many recursive activations occur, and how the parameterization that occur within the body of that activation.\nHowever, each of these recursive algorithms has a unique structure and form.\n\n#### Performing a Binary Search\n\nConsidering the running time of the binary search algorithm, we observe that a constant number of primitive operations are executed \nat each recursive call of method of a binary search. Hence, the running time is proportional to the number of recursive calls performed.\n\n##### Proposition: The binary search algorithm runs in $O(\\log n)$ rimte for a sorted sequence with $n$ elements.\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 4.3: Recursion Run Amok\n\nLet\u0027s see following recursion method",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "def unique(S, start, stop):\n    \"\"\"Return True if there are no duplicate element in slicke S[start:stop]\"\"\"\n    if stop-start \u003c\u003d 1: return True\n    elif not unique(S, start, stop-1): return False\n    elif not unique(S, start+1, stop): return False\n    else: return S[start] !\u003d S[stop-1]",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\nUnfortunately, this is a terribly inefficient use of recursion. In general case, the important observation is that a single call to `unique` for \na problem of size $n$ may result in two recursive calls on problems of size $n-1$. Those two calls with size $n-1$ could in turn result in four calls with a \n\nrange of size $n-2$, and thus eight calls with size $n-3$ and so on. Thus in the worst case, the total number of function \ncall is given by the geometric summation\n\n$$1 + 2 + 4 + \\cdots + 2^{(n-1)}$$\n\nThus, the running time of the function is $O(2^n)$.\n\n#### An Inefficient Recursion for Computing Fibonacci Numbers\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "outputs": [],
      "source": "def bad_fibonacci(n):\n    counter(bad_fibonacci)\n    if n \u003c\u003d 1:\n        return n\n    else:\n        return bad_fibonacci(n-2) + bad_fibonacci(n-1)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "outputs": [],
      "source": "def counter(func):\n    func.count +\u003d 1",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "outputs": [],
      "source": "num_called \u003d list()\nfor i in range(30):\n    bad_fibonacci.count \u003d 0\n    bad_fibonacci(i)\n    num_called.append(bad_fibonacci.count)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "outputs": [
        {
          "data": {
            "text/plain": "[1,\n 1,\n 3,\n 5,\n 9,\n 15,\n 25,\n 41,\n 67,\n 109,\n 177,\n 287,\n 465,\n 753,\n 1219,\n 1973,\n 3193,\n 5167,\n 8361,\n 13529,\n 21891,\n 35421,\n 57313,\n 92735,\n 150049,\n 242785,\n 392835,\n 635621,\n 1028457,\n 1664079]"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 50
        }
      ],
      "source": "num_called",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "You can see this approach requires incredibly inefficient!\n\n#### An Efficient Recursion for Computing Fibonacci Numbers\n\nWe can compute Fibonacci much more efficiently using a recursion in which each invocation makes only one \nrecursive call. To do so, we need to redefine the expectations of the function.\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "outputs": [],
      "source": "def good_fibonacci(n):\n    counter(good_fibonacci)\n    if n\u003c\u003d 1:\n        return n, 0\n    else:\n        (a, b) \u003d good_fibonacci(n-1)\n        return a+b, a",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "outputs": [],
      "source": "num_called \u003d list()\nfor i in range(30):\n    good_fibonacci.count \u003d 0\n    good_fibonacci(i)\n    num_called.append(good_fibonacci.count)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "outputs": [
        {
          "data": {
            "text/plain": "[1,\n 1,\n 2,\n 3,\n 4,\n 5,\n 6,\n 7,\n 8,\n 9,\n 10,\n 11,\n 12,\n 13,\n 14,\n 15,\n 16,\n 17,\n 18,\n 19,\n 20,\n 21,\n 22,\n 23,\n 24,\n 25,\n 26,\n 27,\n 28,\n 29]"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 56
        }
      ],
      "source": "num_called",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "You can see `good_fibonacci` requires far less computation for getting same value!\n\nThe `bad_fibonacci` function uses exponential time. But `good_fibonacci` takes $O(n)$ time. Each recursive call to \n`good_fibonacci` decreases the argument $n$ by $1$; therefore, a recursion trace includes a series of $n$ function calls. Because the\nnonrecursive work for each call uses constant time, the overall computation executes in $O(n)$ time.\n\n### 4.3.1 Maximum Recursive Depth in Python\n\nAnother danger in the misuse of recursion is known as **infinite recursion**. If each recursive call amkes another recursive call, without ever\n reaching a base case, then we have an infinite series of such calls. This is a fatal error. An infinite recursion cna quickly swamp computing resources, \n not only due to rapid use of the CPU, but because each successive call create an activation record requiring additional memory.\n \nPython itself limits the overall number of function activations that can be simultaneously active. The precise value of this limit depend upon \n the Python distribution, but a typical default value is 1000. If this limit is reached the Python interpreter raises a `RuntimeError` with a message \n `maximum recursion depth exceeded`.\n\nYou can dynamically reconfigure the default recursive limit as follows:\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "outputs": [],
      "source": "import sys\nsys.setrecursionlimit(10000) # change limit to 10000",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 4.4 Further Examples of Recursion\n\n* If a recursive call starts at most one other, we call this a ***linear recursion***.\n* If a recursive call start two others, we call this a ***binary recursion***.\n* If a recursive call may start three or more others, this is ***multiple recursion***.\n\n### 4.4.1 Linear Recursion\n\nIf a recursive function is designed so that each invocation of the body makes at most one new recursive call, this is known as ***linear recursion***.\nA consequence of the definition of linear recursion is that any recursion trace will appear as a single sequence of calls. Note that\n the *linear recursion* terminology reflects the structure of the recursion trace, not the asymptotic analysis of the running time; for example, we have seen that \n binary search runs in $O(\\log n)$ time.\n \n#### Summing the Elements of a Sequence Recursively",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "outputs": [
        {
          "data": {
            "text/plain": "15"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 58
        }
      ],
      "source": "def linear_sum(S, n):\n    \"\"\"Return the sum of the first n numbers of sequence S.\"\"\"\n    if n \u003d\u003d 0:\n        return 0\n    else:\n        return linear_sum(S, n-1) + S[n-1]\n\nlinear_sum([5, 2, 3, 5, 1, 20], 4)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "#### Reversing a Sequence with Recursion",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "outputs": [
        {
          "data": {
            "text/plain": "[6, 5, 4, 3, 2, 1]"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 62
        }
      ],
      "source": "def reverse(S, start, stop):\n    \"\"\"Reverse elements in implicit slice S[start:stop].\"\"\"\n    if start \u003c stop - 1:\n        S[start], S[stop-1] \u003d S[stop-1], S[start]\n        reverse(S, start+1, stop-1)\n\nx \u003d [1, 2, 3, 4, 5, 6]\nreverse(x, 0, 6)\nx",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "#### Recursive Algorithms for Computing Powers\n\nAs another interesting example of the use of linear recursion, we consider the problem of raising a number $x$ to an \narbitrary nonnegative integer, $n$. That is, we wish to compute the **power function** defined as $\\text{power}(x, n) \u003d x^n$.\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "1099511627776\n# Called:  41\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "def power(x, n):\n    \"\"\"Compute the value x**n for integer n.\"\"\"\n    counter(power)\n    if n \u003d\u003d 0:\n        return 1\n    else:\n        return x * power(x, n-1)\n\npower.count \u003d 0\nprint(power(2, 40))\nprint(\"# Called: \", power.count)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "A recursive calls to this version runs in $O(n)$ time. ITs recursion trace has structure very similar to that of the factorial function.\n\nHowever, there is a much faster way to compute the power function using an alternative definition that employs a squaring technique.\n\n$$\n\\text{power}(x, n) \u003d \n\\begin{cases}\n1 \u0026 \\text{if } n \u003d 0 \\\\\nx \\cdot (\\text{power}(x, \\left\\lfloor \\frac{n}{2} \\right\\rfloor ))^2\u0026 \\text{if } n \u003e 0 \\ \\text{is odd}\\\\ \n(\\text{power}(x, \\left\\lfloor \\frac{n}{2} \\right\\rfloor ))^2\u0026 \\text{if } n \u003e 0 \\ \\text{is even}\\\\ \n\\end{cases}$$\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "1099511627776\n# Called:  7\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "def power(x, n):\n    \"\"\"Compute the value x**n for integer n.\"\"\"\n    counter(power)\n    if n \u003d\u003d 0:\n        return 1\n    else:\n        partial \u003d power(x, n//2)\n        result \u003d partial * partial\n        if n%2 \u003d\u003d 1:\n            result *\u003d x\n        return result\n\npower.count \u003d 0\nprint(power(2, 40))\nprint(\"# Called: \", power.count)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "To analyze the running time of the revised algorithm, we observe taht the exponent in each recursive call of function `power(x,n)` is \nat most half of the preceding exponent. As we saw with the analysis of binary search, the number of times that we can divide $n$ in half before getting to one or less is $O(\\log n)$.\nTherefore, our new formulation of the `power` function results in $O(\\log n)$ recursive calls. Each individual activation of the functions uses $O(1)$ operations (excluding the recursive calls), and so the \n total number of operations for computing `power(x,n)` is $O(\\log n)$. THis is a significant improvement over the original $O(n)$-time algorihtm.\n \n Since the recursive depth of the improved ve3rsion is $O(\\log n)$, its memory usage is $O(\\log n)$ as well.\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 4.4.2: Binary Recursion\n\nWhen a function makes two recursive calls, we say that it uses ***binary recursion***.\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "outputs": [
        {
          "data": {
            "text/plain": "1225"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 80
        }
      ],
      "source": "def binary_sum(S, start, stop):\n    \"\"\"Return the sum of the numbers in implicit slice S[start:stop].\"\"\"\n    if start \u003e\u003d stop:\n        return 0\n    elif start \u003d\u003d stop - 1:\n        return S[start]\n    else:\n        mid \u003d (start + stop) // 2\n        return binary_sum(S, start, mid) + binary_sum(S, mid, stop)\n\nbinary_sum(list(range(100)), 0, 50)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "The size of the range is divided in half at each recursive call, and so the depth of the recursion is $1 + \\log_2 n$. Therefore, \n`binary_sum` uses $O(\\log n)$ amount of additional space, which is a big improvement over $O(\\log n)$ space used by the `linear_sum` function. \nHowever, the running time of `binary_sum` is $O(n)$, as there are $2n-1$ function calls, each requiring constant time.\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 4.4.3 Multiple Recursion\n\nGeneralizing from binary recursion, we define ***multiple recursion*** as a process in which a function may make more than two recursive calls.\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 4.5 Designing Recursive Algorithms\n\nIn general, an algorithm that sues recursion typically has the following form:\n\n* Test for base cases\n\n  We begin by testing for a set of base cases (there should be at least one). These base cases should be defined so that every possible chain of recursive calls will eventually reach a base case, \n  and the handling of each base case should not use recursion.\n  \n* Recur. \n\n  If not a base case, we perform one or more recursive calls. This recursive step may involve a test that decides which of several possible recursive \n  calls to make. We should define each possible recursive call so that it makes progress towards a base case.\n  \n#### Parameterizing a Recursion\nTo design a recursive algorithm for a given problem, it is useful to think of the different ways we might define subproblems that have the same general structure as the original problem. \nIf one has difficulty finding the repetitive structure needed to design a recursive algorithm, it is sometimes useful to work out the problem on a few concrete \nexamples to see how the subproblems should be defined.\n\nA successful recursive design sometimes requires that we redefine the original problem to facilitate similar-looking subproblems. \nOften, this involved reparameterizing the signature of the function. For example, when performing a binary search in a sequence, a natural function signature for a caller \nwould appear as `binary_search(data, target)`. However, we defined our function with calling signature `binary_search(data, target, low, high)` using the additional parameters to \ndemarcate sublists as the recursion proceeds. This change in parameterization is critical for binary search. If we had insisted on the cleaner signature, \n`bianry_search(data, target)`, the only way to invoke a search on half the list would have been to make a new list instance with only those elements to send as the first parameter. However, making a copy of half the list would already \ntake $O(n)$ time, negating the whole benefit of the binary search algorithm.\n\nIf we wished to provide a cleaner public interface to an algorithm like binary search, without bothering a user with extra \nparameters, a standard technique is to make one function for public use with the cleaner interface, such as `binary_search(data, target)`, and then having its body invoke a nonpublic utility function having the \ndesired recursive parameters.\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 4.6 Eliminating Tail Recursion\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}